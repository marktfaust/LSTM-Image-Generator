{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "eCQIdRg0gxxf",
        "aS_t-eVVi0Pj",
        "9Zo4kqOlu92s",
        "_W8sp9anMD-y"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marktfaust/LSTM-Image-Generator/blob/main/Mark_Faust_DL_Homework4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework #4: An LSTM-Based Generative Model of Images  (15 Total Points)\n",
        "\n",
        "In this homework, we will work with the LSTM architecture but in a slightly different application than the predominantly text-based ones we discussed in class: image generation.  We can think of an image $\\mathbf{X} \\in \\mathbb{R}^{D \\times D}$ as a time series by re-interpreting one or more of the spatial dimensions as time.  While this might seem strange at first, think of drawing by hand: your pen strokes are naturally ordered by time.  This intuition underlies [*Pixel Recurrent Neural Networks (PixelRNNs)*](https://arxiv.org/abs/1601.06759), which was the state-of-the-art model for image generation around 2016.  In this assignment, we will work with a drastically simplified version of this model, where we take the rows of an image and treat them as a time series, predicting the $t$-th row with a LSTM that has already observed rows $1,\\ldots, t-1$.\n",
        "\n",
        "Let's start by importing the usual libraries...."
      ],
      "metadata": {
        "id": "GgMycBT3JUm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numpy and MatPlotLib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "#PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# PyTorch Utils for Data Processing\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset"
      ],
      "metadata": {
        "id": "jdjN4Y9LRoQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the MNIST dataset"
      ],
      "metadata": {
        "id": "eCQIdRg0gxxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the images on which we'll train the model, we'll use the [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database): 28x28 black-and-white images of handwritten digits.  There are 10 classes corresponding to the digits 0 to 9.  Training on all of them is too costly to do in this homework assignment so we will just get the images that correspond to handwritten 1's."
      ],
      "metadata": {
        "id": "8yDlYzvvPtUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# choose just one class of the MNIST digits to train on\n",
        "# 1's are best for this assignment\n",
        "label_to_get = 1\n",
        "\n",
        "# Dataset: grab only datapoints with the index of 'label_to_get'\n",
        "full_train = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "indices_of_target_label = [i for i, (img, label) in enumerate(full_train) if label == label_to_get]\n",
        "ones_subset = Subset(full_train, indices_of_target_label)"
      ],
      "metadata": {
        "id": "xYwKhJ8xzYJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To verify that we collected the correct subset and to get a sense of what the images look like, let's visualize the first 10 images."
      ],
      "metadata": {
        "id": "5cvSR3KfhcUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the first 10 images\n",
        "plt.figure(figsize=(10, 2))\n",
        "\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i + 1)\n",
        "    plt.imshow(full_train.data[indices_of_target_label[i], :, :], cmap=\"gray\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.suptitle(\"Training Set of MNIST 1's\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v_9kIbMGSY1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the Model  (9 Points)"
      ],
      "metadata": {
        "id": "aS_t-eVVi0Pj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now define an LSTM model that parameterizes an autoregressive model on the *rows* of the above images.  Again, the images above are of size $28 x 28$, and let $\\mathbf{X}_n$ represent the $n$-th image of the training set.  We can decompose $\\mathbf{X}_n$ into rows as $\\mathbf{X}_n = [\\mathbf{x}_{n,1}, \\ldots, \\mathbf{x}_{n,28}]$, where $\\mathbf{x}_{n,t} \\in \\{0, 1\\}^{28}$, meaning that $\\mathbf{x}_{n,t}$ is a 28-dimensional binary vector.  Since there are 28 rows in $\\mathbf{X}_n$, that means we have a time series of 28 elements (i.e. $T=28$), each being a 28-dimensional binary vector.  \n",
        "\n",
        "We can then write the auto-regressive likelihood for one image as:\n",
        "$$ p(\\mathbf{X}_n) \\ = \\ \\prod_{t=1}^{28} p(\\mathbf{x}_{n,t} | \\mathbf{x}_{n,t-1}, \\ldots, \\mathbf{x}_{n,1}).$$  Since the elements of the series are binary vectors, we can parameterize them with the Bernoulli distribution.  We'll have a Bernoulli distribution for each output dimension, but their parameters will all be a function of the LSTM:\n",
        "$$ p(\\mathbf{X}_n) \\ = \\  \\prod_{t=1}^{28} \\prod_{d=1}^{28} \\text{Bernoulli}\\left(x_{n,t,d} ; \\ \\pi_{n,t,d} = \\text{logistic}(\\mathbf{w}^{T}_{d} \\ \\mathbf{h}_{n,t})\\right)$$ $$\\text{ where } \\mathbf{h}_{n,t} = \\text{LSTM}\\left(\\mathbf{h}_{t-1}, \\mathbf{x}_{n,t-1} \\right). $$  This means that each row $\\mathbf{x}_{n,t}$ is input into the LSTM.  The LSTM's hidden state $\\mathbf{h}_{n,t} \\in (0, 1)^{H}$, where $H$ is a user-specified dimensionality.  The hidden state is then multiplied by $\\mathbf{w}_{d} \\in \\mathbb{R}^{H}$ and the output transformed by a logistic inverse link function to produce $\\pi_{t,d}$, the Bernoulli parameter for the pixel in the $t$-th row and $d$-th column.\n",
        "Finally, we can write the training objective as the negative log probability of all $N$ training images:\n",
        "$$ \\ell(\\theta; \\mathbf{X}_{1}, \\ldots, \\mathbf{X}_{N}) \\ = \\ - \\log \\left\\{ \\prod_{n=1}^{N} \\prod_{t=1}^{28} \\prod_{d=1}^{28} \\text{Bernoulli}\\left(x_{n,t,d} ; \\ \\pi_{n,t,d} = \\text{logistic}(\\mathbf{w}^{T}_{d} \\ \\mathbf{h}_{n,t})\\right)  \\right\\} $$ $$ = \\sum_{n=1}^{N} \\sum_{t=1}^{28} \\sum_{d=1}^{28} - x_{n,t,d} \\cdot \\log \\left\\{\\text{logistic}(\\mathbf{w}^{T}_{d} \\ \\mathbf{h}_{n,t}) \\right\\} - (1-x_{n,t,d}) \\cdot \\log \\left\\{ 1 - \\text{logistic}(\\mathbf{w}^{T}_{d} \\ \\mathbf{h}_{n,t}) \\right\\}.$$"
      ],
      "metadata": {
        "id": "f9qVssEoPeWV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem #1** **(7 points)**: Define the model above as a PyTorch class.  [See the documentation on PyTorch's LSTM implementation.](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)"
      ],
      "metadata": {
        "id": "LSxhLY3rrgP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BernoulliLSTM(nn.Module):\n",
        "    def __init__(self, input_dim=28, hidden_dim=128, batch_first=True):\n",
        "        ### INPUT ARGUMENTS ###\n",
        "        # input_dim: dimension of input at each time step\n",
        "        # hidden_dim: dimension of hidden state\n",
        "        # batch_first: If 'True', then the the input and output tensors are provided as (batch, seq, feature).\n",
        "        ### YOUR SOLUTION GOES HERE ###\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### INPUT ARGUMENTS ###\n",
        "        # x: input to the LSTM, which is of size [B, T, D] where B is the batch size, T is the max number of time steps (T=28), and D is the dimensionality of each input vector (D=28)\n",
        "        ### OUTPUTS ###\n",
        "        # Return an output of size [B, T, D] (same values as above), which consists of the Bernoulli parameters Ï€_{t,d}.  Use torch.nn.Sigmoid to implement the logistic function.\n",
        "        ### YOUR SOLUTION GOES HERE ###\n",
        "        # return ???\n",
        "\n"
      ],
      "metadata": {
        "id": "a4nuRQtVgSxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem #2** (2 points): [choose the appropriate PyTorch function](https://pytorch.org/docs/stable/nn.html#loss-functions) to implement the loss function defined above as $\\ell(\\theta; \\mathbf{X}_{1}, \\ldots, \\mathbf{X}_{N})$, where $\\theta$ denotes all the RNN's parameters."
      ],
      "metadata": {
        "id": "CGeZHiLWtz3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# choose the appropriate loss function from https://pytorch.org/docs/stable/nn.html#loss-functions\n",
        "training_loss = ???"
      ],
      "metadata": {
        "id": "z9jEOeOQzrEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the LSTM Model  (5 Points)"
      ],
      "metadata": {
        "id": "9Zo4kqOlu92s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are ready to train the model.  Let's first define a batch size and a [PyTorch DataLoader](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html), which will provide an easy mechanism for iterating over the training batches."
      ],
      "metadata": {
        "id": "cqKoNT00PhsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "train_loader = DataLoader(ones_subset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "imohA9pyScLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's implement the training logic.\n",
        "\n",
        "**Problem #3** **(5 points)**: Implement the optimization step.  We've used this pattern before in discussion exercises, but see if the [PyTorch optim documentation](https://pytorch.org/docs/stable/optim.html) if you need a refersher.  Leave the epoch and step_size parameters to their default values (until your implementation works and you want to explore how different settings impact the results)."
      ],
      "metadata": {
        "id": "9OX91RHoKqW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binarize_batch(batch):\n",
        "  # Given a value between [0,1], this function\n",
        "  # returns a sample from a Bernoulli distribution\n",
        "  # with that input parameter\n",
        "  return torch.bernoulli(batch)\n",
        "\n",
        "\n",
        "### TRAINING HYPERPARAMS ###\n",
        "epochs = 5\n",
        "step_size = 0.001\n",
        "\n",
        "\n",
        "### DEFINE MODEL AND OPTIMIZER ###\n",
        "model = BernoulliLSTM()\n",
        "optimizer = optim.Adam(model.parameters(), lr=step_size)\n",
        "\n",
        "\n",
        "### TRAINING LOOP ###\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    for batch, _ in train_loader:\n",
        "        # sample Bernoullis to make the image pixels in {0, 1}\n",
        "        batch = binarize_batch(batch.squeeze(1))  # [B, 28, 28]\n",
        "        # split the batch into inputs and training targets\n",
        "        input_seq = batch[:, :-1, :]   # [B, 27, 28]\n",
        "        target_seq = batch[:, 1:, :]   # [B, 27, 28]\n",
        "\n",
        "        ### IMPLEMENT THE OPTMIZATION STEP ###\n",
        "        ### YOUR SOLUTION GOES HERE ###\n",
        "        #######################################\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")"
      ],
      "metadata": {
        "id": "clknDYfRzcUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Images  (1 Point)"
      ],
      "metadata": {
        "id": "_W8sp9anMD-y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training, we can now sample new images from the model.  One way is to sample from the Bernoulli distributions we used to define the model:\n",
        "$$ \\hat{x}_{t,d} \\sim \\text{Bernoulli}(x_{t,d}; \\pi_{t,d} = \\text{logistic}(\\mathbf{w}_{d}^{T} \\mathbf{h}_{t})). $$\n",
        "That version is implemented for you below.  When your implementation is working, your samples should look similar to those below.  While not a perfect '1', we should clearly see the sampled white pixels forming a fuzzy vertical line:\n",
        "![sampled_mnist_1s.png](data:image/png;base64,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)  \n",
        "\n",
        "\n",
        "\n",
        "However, we could also perform `greedy' decoding from the model.  This will return the modal pixel-wise configuration and be a deterministic output.  You'll have to implement that version.\n",
        "\n",
        "**Problem #4 (1 point):** Implement 'greedy' decoding, where instead of being sampled, the probabilities are thresholded at the variable 'greedy_threshold'.  This means that if the Bernoulli parameter is above 'greedy_threshold', return the value 1 and 0 otherwise."
      ],
      "metadata": {
        "id": "3WLvC6qIPkok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generation: sample rows autoregressively from Bernoulli distribution\n",
        "def generate_images(n=10, decoding_type=\"sample\", greedy_threshold=0.2):\n",
        "    model.eval()\n",
        "    generated_images = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n):\n",
        "            # initalize the input to all zeros\n",
        "            rows = [torch.zeros(1, 1, 28)]  # start with all-zero row\n",
        "            hidden = None\n",
        "            for _ in range(27):\n",
        "                input_seq = torch.cat(rows, dim=1)  # [1, T, 28]\n",
        "                # propagate the LSTM\n",
        "                out, hidden = model.lstm(input_seq, hidden)\n",
        "                # get the logits\n",
        "                logits = model.output_layer(out[:, -1:, :])\n",
        "                # get the Bernoulli params / success probabilities\n",
        "                probs = torch.sigmoid(logits)\n",
        "\n",
        "                # decoding by sampling from the Bernoulli\n",
        "                if decoding_type == \"sample\":\n",
        "                    sampled_row = torch.bernoulli(probs)\n",
        "\n",
        "                # decoding by deterministic, greedy threshold\n",
        "                elif decoding_type == \"greedy\":\n",
        "                    ### YOUR SOLUTION GOES HERE ###\n",
        "\n",
        "                # add sampled row to image\n",
        "                rows.append(sampled_row)\n",
        "\n",
        "            # collect images\n",
        "            image = torch.cat(rows, dim=1).squeeze().numpy()\n",
        "            generated_images.append(image)\n",
        "\n",
        "    # Plot images\n",
        "    plt.figure(figsize=(10, 2))\n",
        "    for i in range(n):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.imshow(generated_images[i], cmap=\"gray\")\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "YrqGai6Wze0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_images(decoding_type=\"sample\")"
      ],
      "metadata": {
        "id": "1u5W1QtBM9mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_images(decoding_type=\"greedy\")"
      ],
      "metadata": {
        "id": "b994QgRfM-Nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uploading your Solution\n",
        "\n",
        "Turn in your solution via Gradescope (accessed through Canvas).  You need to upload *two* files to two different assignment pages within Gradescope:\n",
        "*   a PDF of your code and solutions as shown in the notebook.  You can generate it via File > Print > Save as PDF.  Make sure all of your code and plotting cells are visible.\n",
        "*   a Python file (file.py).  You can export one from the notebook via File > Download > Download .py."
      ],
      "metadata": {
        "id": "HRktnQlzT691"
      }
    }
  ]
}